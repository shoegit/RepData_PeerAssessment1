var(dosetypeOJ$`2`$len)
var(dosetypeVC$`2`$len)
mean(dosetypeVC$`2`$len)
mean(dosetypeVC$`1`$len)
var(dosetypeVC$`1`$len)
var(dosetypeVC$`0.5`$len)
mean(dosetypeVC$`0.5`$len)
q()
mean(dosetypeVC$`0.5`$len)
t.test(gain ~ Diet, paired = FALSE,
)
t.test(len ~ dosetype, paired=FALSE, var.equal=FALSE, data = dosetypeVC$`2`)
t.test(len ~ dosetype, paired=FALSE, var.equal=FALSE, data = dosetypeVC$`2`$len)
?t.test
t.test(len ~ dosetype, paired=FALSE, var.equal=FALSE)
t.test(dosetypeVC$`2`$len, dosetypeOJ$`2`$len, paired=FALSE, var.equal=FALSE)
t.test(dosetypeVC$`2`$len, dosetypeOJ$`2`$len, paired=FALSE, var.equal=FALSE)
?t.test
t.test(dosetypeOJ$`2`$len, dosetypeOJ$`1`$len, paired=FALSE, var.equal=FALSE)
t.test(dosetypeOJ$`2`$len, dosetypeOJ$`1`$len, alternative = "greater", paired=FALSE, var.equal=FALSE)
t.test(dosetypeOJ$`2`$len, dosetypeOJ$`1`$len, alternative = "greater", paired=FALSE, var.equal=TRUE)
t.test(dosetypeOJ$`2`$len, dosetypeOJ$`1`$len, alternative = "greater", paired=FALSE, var.equal=FALSE)
q()
t.test(1:10, y = c(7:20))      # P = .00001855al=FALSE)
t.test(1:10, y = c(7:20, 200)) # P = .1245    -- NOT significant anymore
## Classical example: Student's sleep data
plot(extra ~ group, data = sleep)
## Traditional interface
with(sleep, t.test(extra[group == 1], extra[group == 2]))
## Formula interface
t.test(extra ~ group, data = sleep)
?qt
qt(0.95, df=14.04)
qt(0.975, df=14.04)
qt(0.95, df=18)
qt(0.95, df=18, lower.tail=FALSE)
q()
library(swirl)
swirl()
info()
bye()
q()
?t.test
1100 + c(-1,1) + qt(0.95, 8) * 30/ sqrt(9)
1100 + c(-1,1) * qt(0.95, 8) * 30/ sqrt(9)
1100 + c(-1,1) * qt(0.95, 9-1) * 30/ sqrt(9)
-2 + c(-1,1) * qt(0.95, 9-1) * 2.6/ sqrt(9)
-2 + c(-1,1) * qt(0.95, 9-1) * 1.5/ sqrt(9)
-2 + c(-1,1) * qt(0.95, 9-1) * 0.3/ sqrt(9)
-2 + c(-1,1) * qt(0.95, 9-1) * 2.1/ sqrt(9)
X1<-132.86
S1<-15.34
X1<-127.44
S2<-18.23
N1<-8
N2<-21
sp<-sqrt(((N1-1) * S1&2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1<-132.86
X2<-127.44
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
sp<-sqrt(((N1-1) * S1&2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
sp<-sqrt(((N1-1) * S1^2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1<-3
N1<-10
S1<-0.6
X2<-5
N1<-10
S2<-0.68
N2<-10
sp<-sqrt(((N1-1) * S1^2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1 - X2 + c(-1, 1) * qt(0.95, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
(6-4)/sqrt(4/10+0.5^2/10)
X1<--3
X2<-1
S1<-1.5
S2<-1.8
N1<-9
N2<-9
sp<-sqrt(((N1-1) * S1^2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.95, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1 - X2 + c(-1, 1) * qt(0.90, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
1100 + c(-1,1) + qt(0.975, 8) * 30/ sqrt(9)
1100 + c(-1,1) * qt(0.975, 8) * 30/ sqrt(9)
sp<-sqrt(((N1-1) * S1^2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.90, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1<-3
X2<-5
S1<-sqrt(0.6)
S2<-sqrt(0.68)
N1<-10
N2<-10
sp<-sqrt(((N1-1) * S1^2 + (N2 - 1) * S2^2) / (N1 + N2 - 2))
X1 - X2 + c(-1, 1) * qt(0.90, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1 - X2 + c(-1, 1) * qt(0.95, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1 - X2 + c(-1, 1) * qt(0.975, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
X1 - X2 + c(-1, 1) * qt(0.90, N1+N2-2)*sp*(1/N1 + 1/N2)^.5
q()
swirl()
library(swirl)
swirl()
swirl()
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z<-qnorm(0.95)
pnorm(30+z, mean=30, lower.tail=FALSE)
pnorm(30+z, mean=32, lower.tail=FALSE)
pnorm(30+z, mean=32, sd=1, lower.tail=FALSE)
pnorm(30+z*2, mean=32, sd=2, lower.tail=FALSE)
power.t.test(n=16, delta=2/4, sd=1, type="one.sample", alt="one.sided")$power)
power.t.test(n=16, delta=2/4, sd=1, type="one.sample", alt="one.sided")$power
power.t.test(n=16, delta=2, sd=4, type="one.sample", alt="one.sided")$power
power.t.test(n=16, delta=100, sd=200, type="one.sample", alt="one.sided")$power
power.t.test(power=.8, delta=2/4, sd=1, type="one.sample", alt="one.sided")$n
power.t.test(power=.8, delta=2, sd=4, type="one.sample", alt="one.sided")$n
power.t.test(power=.8, delta=100, sd=200, type="one.sample", alt="one.sided")$n
power.t.test(power=.8, n=26, sd=1, type="one.sample", alt="one.sided")$delta
power.t.test(power=.8, n=27, sd=1, type="one.sample", alt="one.sided")$delta
q()
baseline<-c(140, 138, 150, 148, 135)
after<-c(132, 135, 151, 146, 130)
t.test(baseline, after, paired=TRUE)
t.test(baseline, after, paired=TRUE, alternative="o", lower.tail=TRUE)
t.test(baseline, after, paired=TRUE, alternative="less", lower.tail=TRUE)
t.test(baseline, after, paired=TRUE, alternative="less")
1100 + c(-1,1) * qt(0.95)*sd/sqrt(n)
qt(0.95, 8)
1100 + c(-1,1) * qt(0.95, 8)*30/sqrt(9)
1100 + c(-1,1) * qt(0.975, 8)*30/sqrt(9)
?pexact
pfisher
?pfisher
pbinom(3,4,0.75,lower.tail=FALSE)
swirl()
library(swirl)
swirl()
3
info()
main()
pValues
head(pValues)
sum(pValues<0.05)
p.adjust("bonferroni")
sum(p.adjust(pValues, method="bonferroni")<0.05)
sum(p.adjust(pValues, method="bh")<0.05)
sum(p.adjust(pValues, method="BGH")<0.05)
sum(p.adjust(pValues, method="BH")<0.05)
tail(trueStatus)
table(pValues2<0.05, trueStatus)
24/1000
24/500
table(p.adjust(pValues2,<0.05, trueStatus)
table(p.adjust(pValues2<0.05, trueStatus)
method="bonferroni")
method="bonferroni")
table(pValues2,<0.05, trueStatus)
table(pValues2, trueStatus)
table(p.adjust(pValues2, method="bonferroni")<0.05, trueStatus)
table(p.adjust(pValues2, method="BH")<0.05, trueStatus)
p(0.5)
0.5
sum(1\:6)/6
sum(1:6)/6
print(g2)
head(sh)
head(nh)
nh
median(resampledMedians)
median(sh)
sam<-sample(fh, nh*B, replace=TRUE)
resam<-matrix(B, nh)
resam<-matrix(sam,B, nh)
apply(resam, 1, median)
meds<-apply(resam, 1, median)
median(fh)-median(meds)
sd(meds)
sd(resam)
sd(meds)
sd(resampledMedians))
sd(resampledMedians)
quantile(resampledMedians, c(0.025,.0975)
)
quantile(resampledMedians, c(.025,.975))
quantile(meds, c(.025,.975))
dim(InsetSprays)
dim(InsetcSprays)
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcoutns
BCcouns
BCcounts
group
testStat
obs<-testStat(BCcounts, group)
obs
mean(Bdata$count-Cdata$count)
sample(group)
perms<-sapply(1:10000, function(i) testStat(BCcounts, sample(group)))
perms>obs
mean(perms>obs)
testStat(DEcounts, group)
perms<-sapply(1:10000, function(i) testStat(DEcounts, sample(group)))
q()
ppois(1/100, 10/1787)
1/100
1/1787
10/1787
ppois(1/100, 10/1787, lower.tail=FALSE)
ppois(1/100, 10/1787, lower.tail=TRUE)
10/1787*100
lam<-10/1787*100
lam
ppois(9, lam, lower.tail=FALSE)
0.05*100
10/1787
10/1787*100
ppois(9, lam, lower.tail=TRUE)
pnorm(0.1, lam, lower.tail=FALSE)
pnorm(0.1, lam, lower.tail=TRUE)
pbinom(0.1, lam, lower.tail=TRUE)
pgauss(0.1, lam, lower.tail=TRUE)
1/100
lam<-10/1787
lam
ppois(lam*100 - 1, 1, lower.tail=FALSE)
10/1787*100
ppois(lam*100, 0.1*100, lower.tail=FALSE)
ppois(lam*100, 0.1*100, lower.tail=TRUE)
1/100
ppois(10/1787, 0,01, lower.tail=FALSE)
ppois(10/1787, 0,01, lower.tail=TRUE)
pnorm(10/1787, 0,01, lower.tail=TRUE)
pt(10/1787, 0,01, lower.tail=TRUE)
> mean.diff = 17.5 - 20.1
> df = 10 + 10 - 2
> pooled.var = (2.95^2 * 9 + 2.13^2 * 9) / df
> se.diff = sqrt(pooled.var/10 + pooled.var/10)
> t.obt = mean.diff / se.diff
> t.obt
[1] -2.259640
> p.value = 2*pt(t.obt,df=df)          # two-tailed
> p.value
[1] 0.03648139
mean.diff=-3-1
df = 9 + 9 - 2
se.diff = sqrt(1.5^2/9 *  + 1.8^2 / 9)
t.obt = mean.diff / se.diff
t.obt
p.value = 2*pt(t.obt,df=df)          # two-tailed
p.value
t.obt
p.value
mean.diff=-3-1
se.diff = sqrt(1.5^2/9 *  + 1.8^2 / 9)
t.obt = mean.diff / se.diff
df
pt(t.obt, df)
se.diff = sqrt(1.5^2/9 *  + 1.8^2 / 9)
power <- pnorm(10 + qnorm(.95) * .4, mean = 11, sd = .4, lower.tail = FALSE)
power <- pnorm(0 + qnorm(.95) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
power
power <- pnorm(0 + qnorm(.95) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
n <- (qnorm(.95) + qnorm(.9)) ^ 2 * .04 ^ 2 / .01^2
n
n <- (qnorm(.95) + qnorm(.8)) ^ 2 * .04 ^ 2 / .01^2
n
power <- pnorm(0 + qnorm(.95) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
power <- pnorm(0 + qnorm(.90) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
power
power <- pnorm(0 + qnorm(.95) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
power
power <- pnorm(0 + qnorm(.95) * .04, mean = 0.01, sd = .04, lower.tail = FALSE)
pnorm(15800 / 30, mean = 520, sd = sqrt(520 / 30), lower.tail = FALSE
)
pnorm(1787 / 10, mean = 100/10, sd = sqrt(100/10 / 10), lower.tail = FALSE)
q()
swirl()
library(swirl)
swirl()
info()
bye()
swirl()
swirl()
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
utils:::menuInstallPkgs()
setRepositories()
setRepositories()
chooseCRANmirror()
swirl()
Sys.getlocate("LC_TIME")
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day<-today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label=TRUE))
wday(this_day, label=TRUE)
this_moment<-now()
this_moment
hour(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
dmy("25081985")
dmy("192012")
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours=8, minutes=34, seconds=55)
this_moment
this_moment<-update(this_moment, hours=2, minutes=10)
this_moment
?now
now(tzone="America/New_York")
now("America/New_York")
nyc<-now("America/New_York")
nyc
depart<-nyc + days(2)
depart
update(depart, hours=17, minutes=34)
depart<-update(depart, hours=17, minutes=34)
depart
arrive<-depart+hours(15)+minutes(50)
?with_tz
with_tz(arrive, "Asia/Hong_Kong")
arrive<-with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time<-mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval()
?new_interval
how_long<-new_interval(last_time, arrive)
as.long(how_long)
as.period(how_long)
stopwatch()
q()
library(swirl)
swirl()
dist(dataFrame)
hc<-hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h=1.5, col="blue")
abline(h=0.4, col="red")
5
5
12
abline(h=0.05, col="green")
quit()
setwd("D:/HELP/BigData/Coursera/ReproducibleResearch/RepData_PeerAssessment1")
file<-unz("activity.zip")
file<-unz(temp, "activity.zip")
temp<-tempfile() file<-unz(temp, "activity.zip")
temp<-tempfile()
file<-unz(temp, "activity.zip")
activityData<-read.csv(temp)
activityData<-read.csv(file)
temp <- tempfile()
download.file("https://github.com/shoegit/RepData_PeerAssessment1/activity,zip",temp)
data <- read.table(unz(temp, "a1.dat"))
unlink(temp)
temp <- tempfile()
download.file("https://github.com/shoegit/RepData_PeerAssessment1/activity.zip",temp)
download.file("https://github.com/shoegit/RepData_PeerAssessment1/blob/master/activity.zip",temp)
data<-read.csv(temp)
data
file<-unz(temp, "activity.zip")
temp
data<-read.csv(temp)
data
ls
temp<-tempfile()
data<-read.table(unz("activity.zip",
temp))
data<-read.table(unz("activity.zip",temp))
temp<-tempfile()
temp<-unzip("activity.zip")
temp
data<-read.csv(temp)
data
unlink(temp)
data
data
data
head(data)
library(dplyr)
steps<-tbl_df(data)
steps
glimpse(steps)
summary(data)
steps %>% group_by(date) %>% summarise(mean(steps))
stepsData<-tbl_df(data)
view(stepsData)
glimpse
glimpse(stepsData)
steps %>% group_by(date)
steps %>% group_by(date) %>% summarise(total=sum(steps))
stepsData %>% group_by(date) %>% summarise(total=sum(steps))
stepsData %>% filter(steps !is.na) %>% group_by(date) %>% summarise(total=sum(steps))
stepsData %>% filter(!is.na(steps)) %>% group_by(date) %>% summarise(total=sum(steps))
dailySteps<-stepsData %>% filter(!is.na(steps)) %>% group_by(date) %>% summarise(total=sum(steps))
dailySteps
hist(dailySteps)
hist(dailySteps, date)
hist(dailySteps$total)
hist(dailySteps$total)
barplot(dailySteps)
barplot(table(dailySteps)
)
hist(dailySteps, density=steps, xlab=date)
dailySteps
hist(dailySteps$total, xlab=dailySteps$date)
barplot(dailySteps$total, xlab=dailySteps$date)
hist(dailySteps$total, xlab=dailySteps$date)
hist(dailySteps$total, xlab="Total number of steps")
hist(dailySteps$total, xlab="Total number of steps", main= "Total Steps Taken Per Day")
mean(dailysteps$total)
mean(dailyTteps$total)
mean(dailySteps$total)
median(dailySteps$total)
data
hourlySteps <- stepsData %>% filter(!is.na(steps))  %>% group_by() %>% summarise(total=sum(steps))
stepsData
hourlySteps <- stepsData %>% filter(!is.na(steps))  %>% group_by(interval) %>% summarise(avg=mean(steps))
hourlySteps
plot(hourlySteps$interval, hourlySteps$avg, type="l")
?plot
plot(hourlySteps$interval, hourlySteps$avg, type="l", main="Average steps by interval", xlab="Interval", ylab="Steps")
data
head(data)
count(data, is.na(steps))
count(data, is.na(steps)=TRUE)
count(data, is.na(steps)==TRUE)
naValues<-filter(data, is.na(steps))
avalues
count(navalues)
count(naValues)
NumRows<-count(naValues)
NumRows
sum(is.na(data$steps))
head(stepsData)
mat<-matrix(1:20, 5,4)
mat
mat[1,2] <- NA
mat
na.handling(mat)
data
head(data)
data2<-data
mean(data2$steps)
filter(data2, interval==0)
?median
median(data2$steps, na.rm=TRUE)
data
data2
median(data2$steps[interval==1250], na.rm=TRUE)
filter(data2, interval==1250)
median(filter(data2, interval==1250)$steps, na.rm=TRUE)
mean(data2$steps[interval==1250], na.rm=TRUE)
mean(filter(data2, interval==1250)$steps, na.rm=TRUE)
data2$steps[is.na(data2$steps)]<-mean(data2$steps[interval==data2$interval], na.rm=TRUE)
mean(filter(data2, interval==1250)$steps, na.rm=TRUE)
data2$steps=mean(filter(data, interval==data2$interval)$steps, na.rm=TRUE)
head(data2)
data2<-data
head(data2)
data2$steps[is.na(data2$steps)]=median(filter(data, interval==data2$interval)$steps, na.rm=TRUE)
head(data2)
data2$steps[is.na(data2$steps)]=median(filter(data, data$interval==data2$interval)$steps, na.rm=TRUE)
head(data2)
data2<-data
head(data2)
data2$steps[is.na(data2$steps)]=median(filter(data, data$interval==data2$interval)$steps, na.rm=TRUE)
head(data2)
data2<-stepsData
# Now replace NA values in second data set with median of the values in the same 5-minute interval
data2$steps[is.na(data2$steps)]=median(filter(stepsData, stepsData$interval==data2$interval)$steps, na.rm=TRUE)
head(data2)
hourlySteps <- data2 %>% filter(!is.na(steps))  %>% group_by(interval) %>% summarise(avg=mean(steps))
plot(hourlySteps$interval, hourlySteps$avg, type="l", main="Average steps by interval", xlab="Interval", ylab="Steps")
dailySteps <- data2 %>% filter(!is.na(steps))  %>% group_by(date) %>% summarise(total=sum(steps))
hist(dailySteps$total, xlab="Total number of steps", main= "Total Steps Taken Per Day")
| With NA values | Removed NA values
meanNoNA
weekday(data2$date)
weekdays(data2$date)
?weekdats
?weekdays
weekdays(data2$date, abbreviate=FALSE)
head(data2)
mutate(data2, weekday = weekdays(data2$date))
data2date
data2$date
weekdays(data2$date)
weekdays(data2.date)
